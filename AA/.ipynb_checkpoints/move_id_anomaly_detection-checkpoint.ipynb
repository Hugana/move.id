{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1120ac7-8a43-46c1-989f-127e92c674dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paho.mqtt import client as mqtt_client\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from adtk.detector import SeasonalAD\n",
    "from adtk.data import validate_series\n",
    "import pandas as pd\n",
    "from adtk.detector import LevelShiftAD\n",
    "from adtk.detector import QuantileAD\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from adtk.detector import OutlierDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ed80530-fc5d-4f84-8193-16464bad9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_message_data_append(topic, row):\n",
    "    # Replace forward slash with underscore in the topic name to create a valid filename\n",
    "    topic_filename = topic.replace('/', '_')\n",
    "    csv_file = f\"data_csv_{topic_filename}.csv\"\n",
    "\n",
    "    if not os.path.exists(csv_file):\n",
    "        # If the file does not exist, create it and write the header\n",
    "        with open(csv_file, mode='w', newline='') as file:\n",
    "            file.write('date,x,y,z\\n')\n",
    "    \n",
    "    # Read the CSV file into a DataFrame or create an empty DataFrame if the file is just created\n",
    "    df = pd.read_csv(csv_file) if os.path.exists(csv_file) else pd.DataFrame(columns=['date', 'x', 'y', 'z'])\n",
    "\n",
    "    # Check the row count and drop the oldest row if necessary\n",
    "    if len(df) >= 120:\n",
    "        df = df.drop(0)\n",
    "\n",
    "    # Create a dictionary for the new row\n",
    "    new_row = {'date': row[0], 'x': row[1], 'y': row[2], 'z': row[3]}\n",
    "\n",
    "    # Append the new row to the DataFrame and save it back to the CSV file\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f9b07ff-fded-4739-a1c1-705e76ecd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getanomalyList(anomalies):\n",
    "    \n",
    "    # Filter out NaN values from anomalies\n",
    "    non_nan_anomalies = anomalies.dropna()\n",
    "    \n",
    "    anomalies_dates = []\n",
    "    \n",
    "    # Append the dates of the anomalies of the x-axis\n",
    "    for anomaly_idx, anomaly in non_nan_anomalies.items():\n",
    "        if anomaly:\n",
    "            anomalies_dates.append(anomaly_idx)\n",
    "\n",
    "    return anomalies_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11c17393-feed-4635-bbe2-6eb9924a37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnomalysLevelShift(topic):\n",
    "    \n",
    "    csv_file = f\"data_csv_{topic}.csv\"\n",
    "    \n",
    "    sleeping_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert 'date' column to datetime\n",
    "    sleeping_data['date'] = pd.to_datetime(sleeping_data['date'])\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    sleeping_data.set_index('date', inplace=True)\n",
    "\n",
    "    # get each axis data\n",
    "    x_axis_data = sleeping_data[\"x\"]\n",
    "    y_axis_data = sleeping_data[\"y\"]\n",
    "    z_axis_data = sleeping_data[\"z\"]\n",
    "    \n",
    "    # validating series\n",
    "    x_train = validate_series(x_axis_data)\n",
    "    y_train = validate_series(y_axis_data)\n",
    "    z_train = validate_series(z_axis_data)\n",
    "\n",
    "    # Create and fit the LevelShiftAD detector for x_train\n",
    "    level_shift_ad_x = LevelShiftAD(c=6.0, side='both', window=3)\n",
    "    anomalies_x = level_shift_ad_x.fit_detect(x_train)\n",
    "    anomalies_x_dates = getanomalyList(anomalies_x) # list of anomalies\n",
    "    \n",
    "    # Create and fit the LevelShiftAD detector for y_train\n",
    "    level_shift_ad_y = LevelShiftAD(c=6.0, side='both', window=3)\n",
    "    anomalies_y = level_shift_ad_y.fit_detect(y_train)\n",
    "    anomalies_y_dates = getanomalyList(anomalies_y) # list of anomalies\n",
    "    \n",
    "    # Create and fit the LevelShiftAD detector for z_train\n",
    "    level_shift_ad_z = LevelShiftAD(c=6.0, side='both', window=3)\n",
    "    anomalies_z = level_shift_ad_z.fit_detect(z_train)\n",
    "    anomalies_z_dates = getanomalyList(anomalies_z) # list of anomalies\n",
    "    \n",
    "    return anomalies_x_dates, anomalies_y_dates, anomalies_z_dates\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "126d974f-94a8-4a3e-89ea-e3905b178ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnomalyQuantile(topic):\n",
    "    \n",
    "    csv_file = f\"data_csv_{topic}.csv\"\n",
    "    \n",
    "    sleeping_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert 'date' column to datetime\n",
    "    sleeping_data['date'] = pd.to_datetime(sleeping_data['date'])\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    sleeping_data.set_index('date', inplace=True)\n",
    "\n",
    "    # get each axis data\n",
    "    x_axis_data = sleeping_data[\"x\"]\n",
    "    y_axis_data = sleeping_data[\"y\"]\n",
    "    z_axis_data = sleeping_data[\"z\"]\n",
    "    \n",
    "    # validating series\n",
    "    x_train = validate_series(x_axis_data)\n",
    "    y_train = validate_series(y_axis_data)\n",
    "    z_train = validate_series(z_axis_data)\n",
    "\n",
    "    # Create and fit the QuantileAD detector for x_train\n",
    "    quantile_ad_x = QuantileAD(high=0.99, low=0.02)\n",
    "    anomalies_x = quantile_ad_x.fit_detect(x_train)\n",
    "    anomalies_x_dates = getanomalyList(anomalies_x) # list of anomalies\n",
    "\n",
    "    # Create and fit the QuantileAD detector for y_train\n",
    "    quantile_ad_y = QuantileAD(high=0.99, low=0.02)\n",
    "    anomalies_y = quantile_ad_y.fit_detect(y_train)\n",
    "    anomalies_y_dates = getanomalyList(anomalies_y) # list of anomalies\n",
    "\n",
    "\n",
    "    # Create and fit the QuantileAD detector for z_train\n",
    "    quantile_ad_z = QuantileAD(high=0.99, low=0.02)\n",
    "    anomalies_z = quantile_ad_z.fit_detect(z_train)\n",
    "    anomalies_z_dates = getanomalyList(anomalies_z) # list of anomalies\n",
    "\n",
    "    return anomalies_x_dates, anomalies_y_dates, anomalies_z_dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5735d61b-a7da-404b-9019-3adde10c08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutlierDetection(id):\n",
    "    \n",
    "    csv_file = f\"data_csv_{topic}.csv\"\n",
    "    \n",
    "    sleeping_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert 'date' column to datetime\n",
    "    sleeping_data['date'] = pd.to_datetime(sleeping_data['date'])\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    sleeping_data.set_index('date', inplace=True)\n",
    "\n",
    "    # get each axis data\n",
    "    x_axis_data = sleeping_data[\"x\"]\n",
    "    y_axis_data = sleeping_data[\"y\"]\n",
    "    z_axis_data = sleeping_data[\"z\"]\n",
    "    \n",
    "    # validating series\n",
    "    x_train = validate_series(x_axis_data)\n",
    "    y_train = validate_series(y_axis_data)\n",
    "    z_train = validate_series(z_axis_data)\n",
    "\n",
    "    x_train_df = pd.DataFrame(x_train)\n",
    "    y_train_df = pd.DataFrame(y_train)\n",
    "    z_train_df = pd.DataFrame(z_train)\n",
    "    \n",
    "    outlier_detector_x = OutlierDetector(LocalOutlierFactor(contamination=0.04))\n",
    "    anomalies_x = outlier_detector_x.fit_detect(x_train_df)\n",
    "    anomalies_x_dates = getanomalyList(anomalies_x) # list of anomalies\n",
    "    \n",
    "    outlier_detector_y = OutlierDetector(LocalOutlierFactor(contamination=0.04))\n",
    "    anomalies_y = outlier_detector_y.fit_detect(y_train_df)\n",
    "    anomalies_y_dates = getanomalyList(anomalies_y) # list of anomalies\n",
    "   \n",
    "    \n",
    "    outlier_detector_z = OutlierDetector(LocalOutlierFactor(contamination=0.04))\n",
    "    anomalies_z = outlier_detector_z.fit_detect(z_train_df)\n",
    "    anomalies_z_dates = getanomalyList(anomalies_z) # list of anomalies\n",
    "\n",
    "    return anomalies_x_dates, anomalies_y_dates, anomalies_z_dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "47e933b3-fd96-4675-83a3-87e3196057fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_anomaly_in_rows(anomaly_timestamps, csv_file, rows):\n",
    "\n",
    "    # Check if the list is empty\n",
    "    if not anomaly_timestamps:\n",
    "        return False\n",
    "        \n",
    "    df = pd.read_csv(\"normal_data_accelerometer.csv\")\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    # Get the last 6 rows of the data\n",
    "    last_rows = df.tail(rows)\n",
    "\n",
    "    # Check if any of the anomaly timestamps exist within the last 6 seconds of the record\n",
    "    for anomaly_timestamp in anomaly_timestamps:\n",
    "        if anomaly_timestamp in last_rows.index:\n",
    "            return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41473d3c-9794-44fa-9b0a-5bb183d9a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_least_two_true(b1, b2, b3):\n",
    "  # Count the number of True values\n",
    "  true_count = sum([b1, b2, b3])\n",
    "  return true_count >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e5ce4dc9-bac6-4948-b6e1-60539b56a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetection(topic,row):\n",
    "    \n",
    "        on_message_data_append(topic,row)\n",
    "\n",
    "        anomalies_x_dates_ls, anomalies_y_dates_ls, anomalies_z_dates_ls = getAnomalysLevelShift(topic)\n",
    "        anomalies_x_dates_q, anomalies_y_dates_q, anomalies_z_dates_q = getAnomalyQuantile(topic)\n",
    "        anomalies_x_dates_od, anomalies_y_dates_od, anomalies_z_dates_od = getOutlierDetection(topic)\n",
    "\n",
    "        check_x_ls = check_anomaly_in_rows(anomalies_x_dates_ls,topic,6)\n",
    "        check_y_ls = check_anomaly_in_rows(anomalies_y_dates_ls,topic,6)\n",
    "        check_z_ls = check_anomaly_in_rows(anomalies_z_dates_ls,topic,6)\n",
    "        LevelShiftAD = at_least_two_true(check_x_ls, check_y_ls, check_z_ls)\n",
    "\n",
    "        check_x_q = check_anomaly_in_rows(anomalies_x_dates_q,topic,6)\n",
    "        check_y_q = check_anomaly_in_rows(anomalies_y_dates_q,topic,6)\n",
    "        check_z_q = check_anomaly_in_rows(anomalies_z_dates_q,topic,6)\n",
    "        QuantileAD = at_least_two_true(check_x_q, check_y_q, check_z_q)\n",
    "     \n",
    "        check_x_od = check_anomaly_in_rows(anomalies_x_dates_od,topic,6)\n",
    "        check_y_od = check_anomaly_in_rows(anomalies_y_dates_od,topic,6)\n",
    "        check_z_od = check_anomaly_in_rows(anomalies_z_dates_od,topic,6)\n",
    "        OutlierDetection = at_least_two_true(check_x_od, check_y_od, check_z_od)\n",
    "\n",
    "        return at_least_two_true(LevelShiftAD,QuantileAD,OutlierDetection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04457c06-e325-4070-8be9-92a2109e55a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugod\\AppData\\Local\\Temp\\ipykernel_18772\\4122871618.py:13: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  client = mqtt_client.Client(mqtt_client.CallbackAPIVersion.VERSION1,client_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MQTT Broker!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_csv_move_id/AA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     client\u001b[38;5;241m.\u001b[39mloop_forever()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     run()\n",
      "Cell \u001b[1;32mIn[113], line 41\u001b[0m, in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m client \u001b[38;5;241m=\u001b[39m connect_mqtt()\n\u001b[0;32m     40\u001b[0m subscribe(client)\n\u001b[1;32m---> 41\u001b[0m client\u001b[38;5;241m.\u001b[39mloop_forever()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:2291\u001b[0m, in \u001b[0;36mClient.loop_forever\u001b[1;34m(self, timeout, retry_first_connection)\u001b[0m\n\u001b[0;32m   2289\u001b[0m rc \u001b[38;5;241m=\u001b[39m MQTTErrorCode\u001b[38;5;241m.\u001b[39mMQTT_ERR_SUCCESS\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m rc \u001b[38;5;241m==\u001b[39m MQTTErrorCode\u001b[38;5;241m.\u001b[39mMQTT_ERR_SUCCESS:\n\u001b[1;32m-> 2291\u001b[0m     rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop(timeout)\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# We don't need to worry about locking here, because we've\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# either called loop_forever() when in single threaded mode, or\u001b[39;00m\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;66;03m# in multi threaded mode when loop_stop() has been called and\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m     \u001b[38;5;66;03m# so no other threads can access _out_packet or _messages.\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_terminate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2297\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_packet) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   2298\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_messages) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:1680\u001b[0m, in \u001b[0;36mClient._loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MQTTErrorCode\u001b[38;5;241m.\u001b[39mMQTT_ERR_UNKNOWN\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;129;01min\u001b[39;00m socklist[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m pending_bytes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1680\u001b[0m     rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop_read()\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1682\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:2094\u001b[0m, in \u001b[0;36mClient.loop_read\u001b[1;34m(self, max_packets)\u001b[0m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MQTTErrorCode\u001b[38;5;241m.\u001b[39mMQTT_ERR_NO_CONN\n\u001b[1;32m-> 2094\u001b[0m rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packet_read()\n\u001b[0;32m   2095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop_rc_handle(rc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:3137\u001b[0m, in \u001b[0;36mClient._packet_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3135\u001b[0m \u001b[38;5;66;03m# All data for this packet is read.\u001b[39;00m\n\u001b[0;32m   3136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_packet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 3137\u001b[0m rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packet_handle()\n\u001b[0;32m   3139\u001b[0m \u001b[38;5;66;03m# Free data and reset values\u001b[39;00m\n\u001b[0;32m   3140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_packet \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   3142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave_remaining\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   3149\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:3803\u001b[0m, in \u001b[0;36mClient._packet_handle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_pubackcomp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUBCOMP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cmd \u001b[38;5;241m==\u001b[39m PUBLISH:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_publish()\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cmd \u001b[38;5;241m==\u001b[39m PUBREC:\n\u001b[0;32m   3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_pubrec()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:4140\u001b[0m, in \u001b[0;36mClient._handle_publish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4138\u001b[0m message\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;241m=\u001b[39m time_func()\n\u001b[0;32m   4139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mqos \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 4140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_on_message(message)\n\u001b[0;32m   4141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MQTTErrorCode\u001b[38;5;241m.\u001b[39mMQTT_ERR_SUCCESS\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mqos \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\paho\\mqtt\\client.py:4496\u001b[0m, in \u001b[0;36mClient._handle_on_message\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   4494\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_callback_mutex:\n\u001b[0;32m   4495\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4496\u001b[0m         on_message(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_userdata, message)\n\u001b[0;32m   4497\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   4498\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_easy_log(\n\u001b[0;32m   4499\u001b[0m             MQTT_LOG_ERR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCaught exception in on_message: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, err)\n",
      "Cell \u001b[1;32mIn[113], line 29\u001b[0m, in \u001b[0;36msubscribe.<locals>.on_message\u001b[1;34m(client, userdata, msg)\u001b[0m\n\u001b[0;32m     26\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerometerSensor\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     27\u001b[0m row \u001b[38;5;241m=\u001b[39m [time, x, y, z]\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (getDetection(topic,row)):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALERTA O GAJO LEVANTOU - SE !!!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[111], line 3\u001b[0m, in \u001b[0;36mgetDetection\u001b[1;34m(topic, row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetDetection\u001b[39m(topic,row):\n\u001b[1;32m----> 3\u001b[0m         on_message_data_append(topic,row)\n\u001b[0;32m      5\u001b[0m         anomalies_x_dates_ls, anomalies_y_dates_ls, anomalies_z_dates_ls \u001b[38;5;241m=\u001b[39m getAnomalysLevelShift(topic)\n\u001b[0;32m      6\u001b[0m         anomalies_x_dates_q, anomalies_y_dates_q, anomalies_z_dates_q \u001b[38;5;241m=\u001b[39m getAnomalyQuantile(topic)\n",
      "Cell \u001b[1;32mIn[104], line 6\u001b[0m, in \u001b[0;36mon_message_data_append\u001b[1;34m(topic, row)\u001b[0m\n\u001b[0;32m      2\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_csv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(csv_file):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# If the file does not exist, create it and write the header\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      7\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate,x,y,z\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame or create an empty DataFrame if the file is just created\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_csv_move_id/AA.csv'"
     ]
    }
   ],
   "source": [
    "broker = 'broker.emqx.io'\n",
    "port = 1883\n",
    "topic = \"move_id/AA\"\n",
    "client_id = ''\n",
    "\n",
    "def connect_mqtt() -> mqtt_client:\n",
    "    def on_connect(client, userdata, flags, rc):\n",
    "        if rc == 0:\n",
    "            print(\"Connected to MQTT Broker!\")\n",
    "        else:\n",
    "            print(\"Failed to connect, return code %d\\n\", rc)\n",
    "\n",
    "    client = mqtt_client.Client(mqtt_client.CallbackAPIVersion.VERSION1,client_id)\n",
    "    client.on_connect = on_connect\n",
    "    client.connect(broker, port)\n",
    "    return client\n",
    "\n",
    "\n",
    "def subscribe(client: mqtt_client):\n",
    "    def on_message(client, userdata, msg): \n",
    "        \n",
    "        time = datetime.now()\n",
    "        data = json.loads(msg.payload.decode())\n",
    "        x = float(data['accelerometerSensor']['x'])\n",
    "        y = float(data['accelerometerSensor']['y'])\n",
    "        z = float(data['accelerometerSensor']['z'])\n",
    "        row = [time, x, y, z]\n",
    "\n",
    "        if (getDetection(topic,row)):\n",
    "            print(\"ALERTA O GAJO LEVANTOU - SE !!!!!\")\n",
    "        else:\n",
    "            print(\"o gajo esta fixe\")\n",
    "        \n",
    "    client.subscribe(topic)\n",
    "    client.on_message = on_message\n",
    "\n",
    "\n",
    "def run():\n",
    "    client = connect_mqtt()\n",
    "    subscribe(client)\n",
    "    client.loop_forever()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fcccd-2315-4931-8840-3da81e96ffe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
